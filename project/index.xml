<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Stephen Ashmore</title>
    <link>ashmore.io/project/</link>
    <description>Recent content in Projects on Stephen Ashmore</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Sep 2016 17:42:31 -0500</lastBuildDate>
    <atom:link href="ashmore.io/project/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Super Neural Scaler</title>
      <link>/ashmore.io/project/superScaler/</link>
      <pubDate>Mon, 19 Sep 2016 17:42:31 -0500</pubDate>
      
      <guid>/ashmore.io/project/superScaler/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image Compression</title>
      <link>/ashmore.io/project/imagecompression/</link>
      <pubDate>Mon, 19 Sep 2016 16:20:36 -0500</pubDate>
      
      <guid>/ashmore.io/project/imagecompression/</guid>
      <description>&lt;p&gt;Image Compression is a useful tool to save disk space, and computation speed. JPG is a great example of a popular image compression technique. However, can we do better with a machine learning technique like neural networks? I&amp;rsquo;m playing around with neural networks to see how well a technique I call neural inference can compress an image. A few caveats, it will probably be much slower than JPG. Depending on the implementation, you could end up using a lot of &amp;ldquo;feed forwards&amp;rdquo; to generate the uncompressed version of the image, and that is just not good for displaying an image. Users demand super fast display of images, and neural networks may not be the best here.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>